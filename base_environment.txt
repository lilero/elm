autodl部署qwen2.5vl,并进行环境安装。

1.创建新的虚拟环境：
conda create -n qwen2.5vl python=3.12
conda activate qwen2.5vl
pip install torch==2.6.0 torchvision==0.21.0 \
--index-url https://download.pytorch.org/whl/cu118 \
-i https://mirrors.aliyun.com/pypi/simple

2.LLaMA-Factory 安装

source /etc/network_turbo

git clone https://github.com/hiyouga/LLaMA-Factory.git

cd LLaMA-Factory

pip install -e ".[torch,metrics]"

# 检查环境是否安装成功。

llamafactory-cli version

#启动WebUI界面，修改端口号为6006，因为AutoDL用的这个端口号

GRADIO_SERVER_PORT=6006  llamafactory-cli webui

3.模型下载
模型地址：https://www.modelscope.cn/Qwen/Qwen2.5-VL-7B-Instruct
source /etc/network_turbo
pip install modelscope

采用SDK方式下载：
from modelscope import snapshot_download

# 指定模型的下载路径
cache_dir = '/root/autodl-tmp/'
# 调用 snapshot_download 函数下载模型
model_dir = snapshot_download('Qwen/Qwen2-VL-7B-Instruct', cache_dir=cache_dir)

print(f"模型已下载到: {model_dir}")

4.在Qwen上使用LLaMA-Factory框架训练的模型
Qwen安装：
https://github.com/QwenLM/Qwen2.5-VL

source /etc/network_turbo
git clone https://github.com/QwenLM/Qwen2.5-VL
cd Qwen2.5-VL
pip install qwen-vl-utils[decord]
pip install transformers
pip install 'accelerate>=0.26.0'


